{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Physical Oceanographic Data - SIO 221A\n",
    "### Python version of [Sarah Gille's](http://pordlabs.ucsd.edu/sgille/sioc221a/index.html) notes by:\n",
    "#### Bia Villas Bôas (avillasboas@ucsd.edu) & Gui Castelão (castelao@ucsd.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 3:  \n",
    "\n",
    "### **Recap**\n",
    "\n",
    "Last time we talked about some probability density functions, the fact\n",
    "that we often assume Gaussianity, and that often geophysical variables\n",
    "aren't really Gaussian.  We also noted that if we know the mean and\n",
    "standard deviation for a set of variables, then we determine the mean\n",
    "and standard deviation for a summed variable.\n",
    "\n",
    "\n",
    "Wenoted that one of the clever aspects of the pdf is that we can use it\n",
    "to determine an expected value:\n",
    "\n",
    "$$\\begin{equation}\n",
    "E(x(k)) = \\int_{-\\infty}^\\infty xp(x)\\, dx = \\mu_x. \\hspace{3cm} (1)\n",
    "\\end{equation}$$\n",
    "\n",
    "We can also use this for $x^2$ or for $(x-\\mu_x)^2$.\n",
    "$$\\begin{equation}\n",
    "E((x(k)-\\mu_k)^2) = \\int_{-\\infty}^\\infty (x-\\mu_x)^2 p(x)\\, dx = \\sigma_x^2. \\hspace{3cm} (2)\n",
    "\\end{equation}$$\n",
    "\n",
    "###  **Error propagation, and the central limit theorem**\n",
    "\n",
    "We finished with a discussion of the standard deviation of summed\n",
    "variables:\n",
    "If $x(k) = \\sum_{i=1}^{N} a_i x_i(k)$, then the mean of $x$ is\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\mu_x = E(x(k)) = E\\left[\\sum_{i=1}^{N} a_i x_i(k)\\right] = \\left[\\sum_{i=1}^{N} a_i E(x_i(k))\\right] =\n",
    "\\sum_{i=1}^{N} a_i \\mu_i. \\hspace{3cm} (3)\n",
    "\\end{equation}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\sigma_x^2 = E\\left[(x(k)-\\mu_x)^2\\right] =\n",
    "=E\\left[\\sum_{i=1}^{N} a_i (x_i(k)-\\mu_i)\\right]^2\n",
    "= \\sum_{i=1}^{N} a_i^2 \\sigma_i^2. \\hspace{3cm} (4)\n",
    "\\end{equation}$$\n",
    "\n",
    "And we noted that the standard error of the mean is $\\sigma/\\sqrt{N}$.\n",
    "\n",
    "The *standard error of the variance* is $\\sigma^2\\sqrt{2/(N-1)}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Propagation.**\n",
    "The results for the standard error of the mean led to one of the basic\n",
    "rules that we use to determine uncertainties for summed quantities.\n",
    "This is usually referred to as error propagation.\n",
    "If we sum a variety of measures together, then the overall uncertainty\n",
    "will be determined by the square root of the sum of the squares:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\delta_y = \\sqrt{\\sum_{i=1}^{N} a_i^2 \\delta_i^2},\\hspace{3cm} (5)\n",
    "\\end{equation}$$\n",
    "\n",
    "where here we're using $\\delta_i$ to represent the a priori uncertainties.\n",
    "\n",
    "We left off with the question of more complicated computed quantites.\n",
    "What if we have to multiply quantities together?  Then we simply\n",
    "linearize about the value of interest.  So if $y=x^2$, and we have an\n",
    "estimate of the uncertainty in $x$, $\\delta_x$, then we know that locally,\n",
    "near $x_o$, we can expand in a Taylor series:\n",
    "\n",
    "$$\\begin{equation}\n",
    "y(x_o+\\Delta x)=y(x_o) + dy/dx \\Delta x. \\hspace{3cm} (6)\n",
    "\\end{equation}$$\n",
    "\n",
    "This means that I can use my rules for addition to estimate the uncertainty\n",
    "in $y$:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\delta_y(x_o)= \\left|\\frac{dy(x_o)}{dx}\\right| \\delta_x \n",
    "= 2x_o \\delta_x \\hspace{3cm} (7)\n",
    "\\end{equation}$$\n",
    "\n",
    "and you can extend from here.  If $y=a_1 x + a_2 x^2 + a_3 x^3$, what is\n",
    "$\\delta_y$?  When will this estimate of uncertainty break down?\n",
    "\n",
    "Let's consider the specific cases of turbulent heat fluxes.\n",
    "The sensible heat flux is:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "Q_s = c_h (T_w - T_a) W,\\hspace{3cm} (8)\n",
    "\\end{equation}$$\n",
    "\n",
    "where $c_h$ is a constant, $T_w$ is surface water temperature, $T_a$ is air temperature (e.g. at 2m elevation), and $W$ is wind speed. (Of course there are some complications:  $c_h$ is not really a constant.  We can approximate it as: $c_h = \\rho_a C_{p,a} C_h$, where $\\rho_a \\approx 1.2$kgm$^{-3}$ is density of air, the constant pressure specific heat of air $C_{p,a}\\approx 1$kJkg$^{-1}$ $^\\circ$C, and $C_h \\approx 10^{-3}$.)  A typical value for $Q_h$ is -5Wm$^{-2}$.\n",
    "\n",
    "The latent heat flux is:\n",
    "\n",
    "$$\\begin{equation}\n",
    "Q_L = c_e (q_w - q_a) W,\\hspace{3cm} (9)\n",
    "\\end{equation}$$\n",
    "\n",
    "where $c_e$ is a constant, $q_w$ is specific humidity at the water surface, and\n",
    "$q_a$ is specific humidity in air.\n",
    "More completely, we can represent $c_e$ as:\n",
    "\n",
    "$$\\begin{equation}\n",
    "c_e = \\rho_a L_v C_e,\\hspace{3cm} (10)\n",
    "\\end{equation}$$\n",
    "\n",
    "where $L_v = 2264.76$kJkg$^{-1}$ is the latent heat of vaporization,\n",
    "and $C_e\\approx 1.5 \\times 10^{-3}$.  A typical value for $Q_e$ is about -20Wm$^{-2}$.\n",
    "\n",
    "So suppose we measure $T_w$, $T_a$, and $W$ with some uncertainties?  What is the\n",
    "uncertainty in $Q_s$?  To compute this, we simply follow our rules:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\delta(Q_s)^2 &  = & \\left[\\frac{\\partial Q_s}{\\partial T_w}\\right]^2\\delta(T_w)^2 +\n",
    "   \\left[\\frac{\\partial Q_s}{\\partial T_a}\\right]^2\\delta(T_a)^2 +\n",
    "    \\left[\\frac{\\partial Q_s}{\\partial W}\\right]^2\\delta(W)^2  \\hspace{3cm} (11)\\\\\n",
    " & = & c_h^2W^2 \\delta(T_w)^2 + (-1)^2 c_h^2W^2 \\delta(T_a)^2+ c_h^2(T_w-T_a)^2 \\delta(W)^2 \\hspace{3cm} (12)\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "We could further refine this to take into account the uncertainties in $c_h$,\n",
    "which might depend on $\\rho_a$, and the other coefficients.\n",
    "\n",
    "Likewise, the uncertainty in the latent heat flux can be estimated through\n",
    "error propagation, and we can decide how much to build the uncertainties in $L_v$\n",
    "and $C_e$ into our estimate.\n",
    "\n",
    "This formulation for error propagation works like a charm.  But it's built\n",
    "on a few assumptions, and it behooves us to keep these in mind.\n",
    "Namely, we assume that our perturbations are small enough that it's OK to\n",
    "linearize.  And we assume that errors are uncorrelated, so that we can treat\n",
    "each term ($T_w$, $T_a$, and $W$, for example) completely separately.  What do we\n",
    "do if these assumptions break down?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The central limit theorem**\n",
    "\n",
    "One of the reasons we like Gaussian distributions is because of the\n",
    "central limit theorem.  This says that when we sum variables together,\n",
    "the sum will tend to toward being Gaussian, even if the individual\n",
    "variables are not.  And this is plausible, since lots of variables\n",
    "we study are derived quantities and therefore (sort of) Gaussian.\n",
    "Bendat and Piersol discussed summed variables under the heading \"central\n",
    "limit theorem\",\n",
    "but their discussion doesn't provide a clear demonstration of the central\n",
    "limit theorem, and I'm going to leave the formal derivation for 221B.\n",
    "\n",
    "So let's test this empirically:\n",
    "If we start with data drawn from a uniform distribution, and sum together\n",
    "multiple values, how quickly do our results converge to Gaussian?\n",
    "\n",
    "The results of this calculation is shown in the figure below and it\n",
    "provides visual evidence for fairly rapid convergence for the uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "b = np.random.rand(100000,100) -0.5 #define an array with 100 sets of random values,\n",
    "                   #each with 100000 elements\n",
    "cb = np.cumsum(b, axis=1) # compute the summation of multiple random variables\n",
    "\n",
    "bin_max = 12\n",
    "bin_min = -12\n",
    "dbin = 0.1\n",
    "hist_bins = np.arange(bin_min, bin_max, dbin)\n",
    "pdfs = []\n",
    "for i in range(100): \n",
    "    norm_hist, bins = np.histogram(cb[:, i], bins=hist_bins, density=True)\n",
    "    pdfs.append(norm_hist)\n",
    "bins = bins[:-1]\n",
    "pdfs = np.array(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('xtick',labelsize=12)\n",
    "plt.rc('ytick',labelsize=12)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for i in range(5):\n",
    "    plt.plot(bins, pdfs[i], label = 'N = %d' %(i+1))\n",
    "plt.xlim([-5, 5])\n",
    "plt.ylim([0, 1.1])\n",
    "plt.ylabel('probability density', fontsize=14)\n",
    "plt.xlabel('random variable', fontsize=14)\n",
    "plt.legend(loc='best', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability density function for summed data drawn from a uniform distribution. If N = 1, so only one data value is used, the distribution is uniform. If N = 2, is is a triangle distribution. As N increases, the distribution rapidly evolves to more closely resemble a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-Gaussian distributions**\n",
    "\n",
    "As we noted before, unsummed geophysical variables are often non-Gaussian.\n",
    "We've talked about uniform distributions and double exponentials.\n",
    "Here are some particularly important special cases.\n",
    "\n",
    "We noted last time that the Rayleigh distribution is a good representation\n",
    "for wind speed, which is necessarily positive.\n",
    "It is defined from the square root sum of two independent\n",
    "Gaussian components squared, $y=\\sqrt{x_1^2 + x_2^2}$.\n",
    "\n",
    "$$\\begin{equation}\n",
    "p(y)=\\frac{y}{\\sigma^2} \\exp{\\left[-\\frac{y^2}{2\\sigma^2} \\right]}. \\hspace{3cm} (13)\n",
    "\\end{equation}$$\n",
    "\n",
    "And that brings us to the $\\chi^2$ distribution.  Suppose we define\n",
    "a variable:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\chi_n^2 = z_1^2 + z_2^2 + z_3^2 + ... + z_n^2.\\hspace{3cm} (14)\n",
    "\\end{equation}$$\n",
    "\n",
    "Then $\\chi_n^2$ is a random chi-square variable with $n$ degrees of freedom\n",
    "(and $n$ is simply the number of independent elements that we sum.)\n",
    "Then we can define a functional form for this:\n",
    "\n",
    "$$\\begin{equation}\n",
    "p(\\chi_n^2) = \\frac{1}{2^{n/2} \\Gamma(n/2)} \\exp\\left(\\frac{-\\chi^2}{2}\\right)\n",
    "(\\chi^2)^{(n/2)-1},\\hspace{3cm} (15)\n",
    "\\end{equation}$$\n",
    "\n",
    "where $\\Gamma(n/2)$ is the gamma function (and this is a function that\n",
    "you normally access through a look-up table or a function programmed\n",
    "into Matlab, for example).\n",
    "Lots of variables end up looking like $\\chi^2$, so we'll use this a lot\n",
    "to assess uncertainties, and for this we'll need the cumulative\n",
    "distribution function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cumulative distribution functions**\n",
    "\n",
    "The *cumulative distribution function* $C(x)$ is the probability of\n",
    "observing a value less than $x$.  It can be computed by integrating the pdf.\n",
    "\n",
    "$$\\begin{equation}\n",
    "C(x) = \\int_{-\\infty}^x p(x') dx'.\\hspace{3cm} (16)\n",
    "\\end{equation}$$\n",
    "\n",
    "$C(x)$ is 0 when $x$ approaches minus infinity, indicating that there's\n",
    "a negligibly small chance of having an infinitely small value of $x$, and\n",
    "it is 1 when $x$ goes to plus infinity, which says that there is a 100\\%\n",
    "chance of observing some value.  The midpoint, where $C(x)=0.5$ is the\n",
    "median.\n",
    "\n",
    "For a Gaussian, the cdf is defined to be an error function.  For a\n",
    "chi-squared function, it's defined as\n",
    "\n",
    "$$\\begin{equation}\n",
    "C(x) = \\frac{1}{\\Gamma(n/2)} \\gamma(n/2,x/2),\\hspace{3cm} (17)\n",
    "\\end{equation}$$\n",
    "\n",
    "where $\\gamma$ is the lower incomplete Gamma function (and like the Gamma\n",
    "function $\\Gamma(n/2)$, it is accessed through a look-up table.\n",
    "What is the cdf of a uniform distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are two pdfs different?**\n",
    "\n",
    "So now let's return to the heart of our problem.  How do we tell if two\n",
    "pdfs differ?  We've already noted that two data sets can look wildly different\n",
    "but still have the same mean and variance, so clearly we need something more\n",
    "than just the mean and variance.\n",
    "We can go back to our Gaussian overlaid on empirical pdf\n",
    "and eyeball the difference to say that they're close enough, or not\n",
    "plausibly similar.  We can evaluate whether the mean and standard deviation\n",
    "differ.  All of this is good, but it doesn't exploit the full range of\n",
    "information in the pdf.   We\n",
    "need a metric to measure how different two distributions are.\n",
    "\n",
    "Here are a couple of strategies.  One notion is to ask about the largest\n",
    "separation between 2 pdfs.  We compute two cdfs---in this case one\n",
    "empirical and one theoretical, but we can also do this with two empirical\n",
    "cdfs.  We find the maximum separation between the distributions, the Komogorov-Smirnov statistic:\n",
    "\n",
    "$$\\begin{equation}\n",
    "D_n = \\sup_n \\left| C_n(x) - C(x)\\right|\\hspace{3cm} (18)\n",
    "\\end{equation}$$\n",
    "\n",
    "and then we can predict the probability that a data set with $n$ elements\n",
    "should differ from the ideal distribution by $D_n$. The module `scipy.stats` has a the function [`kstest`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.kstest.html)\n",
    "that sorts through the parameters for this.  However, we have to be careful\n",
    "with this, because usually our data are correlated, and we don't have as\n",
    "many degrees of freedom as we think.  The easiest solution is to decimate\n",
    "the data set so that the number of elements reflects the number of\n",
    "degrees of freedom.\n",
    "\n",
    "A second strategy is to bin the data and ask whether the number of\n",
    "data in the bin is consistent with what we'd expect, using a $\\chi^2$\n",
    "statistics.  In this case for comparisons with a theoretical pdf,\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\chi^2 = \\sum_i\\frac{(N_i-n_i)^2}{n_i},\\hspace{3cm} (19)\n",
    "\\end{equation}$$\n",
    "\n",
    "where $N_i$ is the observed number of events in bin $i$, and $n_i$ is the theoretical\n",
    "or expected number of events in bin $i$.\n",
    "For comparisons between two distributions,\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\chi^2 = \\sum_i\\frac{(N_i-M_i)^2}{N_i+M_i}, \\hspace{3cm} (20)\n",
    "\\end{equation}$$\n",
    "\n",
    "where $N_i$ and $M_i$ are each observed numbers of events for bin $i$.\n",
    "The values of $\\chi^2$ are evaluated using the $\\chi^2$ probability function $Q(\\chi^2|\\nu)$, which is an incomplete gamma function,\n",
    "where $\\nu$ is the number of bins (or the number of bins minus one, depending on\n",
    "normalization).  In Python this is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special as spe\n",
    "half_nu = [0.5, 1, 1.5, 2]\n",
    "x = np.arange(0, 10, 0.05)\n",
    "plt.figure(figsize=(8,6))\n",
    "for n in half_nu:\n",
    "    plt.plot(x, spe.gammainc(n, x), label='$\\\\nu/2 =$%.1f' %n)\n",
    "    plt.legend(fontsize=12)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('$Q(\\\\chi,\\\\nu/2)$', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting a function to data:  least-squares fitting**\n",
    "\n",
    "Now, we've laid a lot of ground work.  Let's think about our time series.\n",
    "If we look at SST records, for example, how can we determine whether\n",
    "temperatures are increasing or decreasing over time.  Let's suppose we're\n",
    "looking for a linear trend.  Then\n",
    "\n",
    "$$\\begin{equation}\n",
    "T=T_o + b t, \\hspace{3cm} (21)\n",
    "\\end{equation}$$\n",
    "\n",
    "where $T$ represents our measured temperature data,\n",
    "$T_o$ is a constant (unknown), $t$ is time, and $b$ is the time rate of\n",
    "change.  We have lots of observations, so we really should represent this\n",
    "using vectors (which we'll indicate with bold face):\n",
    "\n",
    "$$\\begin{equation}\n",
    "{\\bf T}=T_o + b {\\bf t}.\\hspace{3cm} (22)\n",
    "\\end{equation}$$\n",
    "\n",
    "We'll want to find the best estimates of the scalars $T_o$ and $b$ to match\n",
    "our data.  Formally, provided that we have more than two measurements, this\n",
    "is an over-determined system.\n",
    "Of course, we're talking about real data, so we should acknowledge\n",
    "that we have noise, and our equations won't be perfect fits.  We could write:\n",
    "\n",
    "$$\\begin{equation}\n",
    "{\\bf T}=T_o + b {\\bf t} + {\\bf n},\\hspace{3cm} (23)\n",
    "\\end{equation}$$\n",
    "\n",
    "where $\\bf n$ represents noise and is unknown.  Now the system is formally\n",
    "underdetermined.  But we won't lose hope.  We'll just move forward under\n",
    "the assumption that the noise is small.\n",
    "\n",
    "Let's write this in a more general form as a matrix equation:\n",
    "\n",
    "$$\\begin{equation}\n",
    "{\\bf Ax} + {\\bf n}= {\\bf y},\\hspace{3cm} (24)\n",
    "\\end{equation}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\begin{equation}\n",
    "{\\bf A} =  \\left[\\begin{array}{cc}\n",
    "                              1 & t_1  \\\\\n",
    "                              1 & t_2  \\\\\n",
    "                              1 & t_3  \\\\\n",
    "                              \\vdots & \\vdots \\\\\n",
    "                              1 & t_N  \\end{array}\\right],\\hspace{3cm} (25)\n",
    "\\end{equation}$$\n",
    "\n",
    "and ${\\bf y}$ is a column vector containing, for example, the $N$ elements of our temperature data:\n",
    "\n",
    "$$\\begin{equation}\n",
    "{\\bf y} =  \\left[\\begin{array}{c}\n",
    "                              T_1  \\\\\n",
    "                              T_2  \\\\\n",
    "                              T_3  \\\\\n",
    "                              \\vdots \\\\\n",
    "                              T_N  \\end{array}\\right].\\hspace{3cm} (26)\n",
    "\\end{equation}$$\n",
    "\n",
    "Then ${\\bf x}$ is the vector of unknown coefficients (e.g. $x_1=T_o$ and\n",
    "$x_2=b$).\n",
    "\n",
    "$$\\begin{equation}\n",
    "{\\bf x} =  \\left[\\begin{array}{c}\n",
    "                              x_1  \\\\\n",
    "                              x_2 \\end{array}\\right] \\hspace{3cm} (27)\\\\\n",
    "\\end{equation}$$\n",
    "\n",
    "How can we find the best solution to this equation to minimize the misfit\n",
    "between the data ${\\bf y}$ and the model ${\\bf Ax}$?   The\n",
    "misfit could be positive or negative, and absolute values aren't mathematically\n",
    "tractable, so let's start by squaring the misfit.\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\epsilon = ({\\bf Ax} - {\\bf y})^T({\\bf Ax} - {\\bf y}) = {\\bf x}^T{\\bf A}^T{\\bf Ax} - 2{\\bf x}^T{\\bf A}^T{\\bf y} + {\\bf y}^T{\\bf y}.\\hspace{3cm} (28)\n",
    "\\end{equation}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
